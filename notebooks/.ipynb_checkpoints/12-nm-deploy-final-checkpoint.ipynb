{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflection\n",
    "import umap as umap\n",
    "import re\n",
    "import s3fs\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition as dd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_s3 = 's3://insiders-dataset-nm'\n",
    "data = pd.read_excel( path_s3 + '/Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
    "       'UnitPrice', 'CustomerID', 'Country']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x ) # change to snakecase\n",
    "cols_new = list( map( snakecase, cols_old ))\n",
    "\n",
    "data.columns = cols_new # define the new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Check and fillout Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA\n",
    "df_missing = data[data['customer_id'].isna()]\n",
    "df_not_missing = data[~data['customer_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reference\n",
    "backup = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "backup['customer_id'] = np.arange(19000, 19000+len(backup), 1)\n",
    "\n",
    "# merge original data frame\n",
    "df1 = pd.merge(data, backup, on='invoice_no', how='left')\n",
    "\n",
    "#coalesce\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "\n",
    "# drop columns\n",
    "df1 = df1.drop(columns=['customer_id_x', 'customer_id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoice data to datetime\n",
    "df1['invoice_date'] = pd.to_datetime(df1['invoice_date'], format='%d-%b-%y')\n",
    "#df1['invoice_date'] = df1['invoice_date'].dt.date\n",
    "\n",
    "# customer id\n",
    "df1['customer_id'] = df1['customer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Filtragem de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit price > 0.04\n",
    "df2 = df2.loc[df2['unit_price'] >= 0.04, :]\n",
    "\n",
    "# stock code \n",
    "df2 = df2[~df2['stock_code'].isin(['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL','PADS', 'B', 'CRUK'])]\n",
    "\n",
    "# description\n",
    "df2 = df2.drop(columns='description', axis=1)\n",
    "\n",
    "#map\n",
    "df2 = df2[~df2['country'].isin(['European Community', 'Unspecified'])]\n",
    "\n",
    "# bad users\n",
    "df2 = df2[~df2['customer_id'].isin([16446])]\n",
    "\n",
    "# quantity - negative numbers means product returns\n",
    "df2_returns = df2.loc[df2['quantity'] < 0, :]\n",
    "df2_purchases = df2.loc[df2['quantity'] >= 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date reference \n",
    "df_ref = df2_purchases.drop(['invoice_no', 'stock_code',\n",
    "                   'quantity', 'invoice_date', 'unit_price', \n",
    "                   'country'], axis=1).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ref.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74118/206990356.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2_purchases.loc[:, 'gross_revenue'] = df2_purchases.loc[:, 'quantity'] * df2_purchases.loc[:, 'unit_price']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gross Revenue ( Faturamento ) quantity * price\n",
    "df2_purchases.loc[:, 'gross_revenue'] = df2_purchases.loc[:, 'quantity'] * df2_purchases.loc[:, 'unit_price']\n",
    "\n",
    "# Monetary\n",
    "df_monetary = df2_purchases.loc[:, ['customer_id', 'gross_revenue']].groupby( 'customer_id' ).sum().reset_index()\n",
    "df_ref = pd.merge( df_ref, df_monetary, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recency - Last day purchase\n",
    "df_recency = df2_purchases.loc[:, ['customer_id', 'invoice_date']].groupby( 'customer_id' ).max().reset_index()\n",
    "df_recency['recency_days'] = ( df2['invoice_date'].max() - df_recency['invoice_date'] ).dt.days\n",
    "df_recency['recency_days'] = df_recency['recency_days'].apply( lambda x: 1/x if x !=0 else 1)\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "df_ref = pd.merge( df_ref, df_recency, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qtde_invoices\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'invoice_no']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id' )\n",
    "                                                             .count()\n",
    "                                                             .reset_index()\n",
    "                                                             .rename( columns={'invoice_no': 'qtde_invoices'}) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qtde_items\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'quantity']].groupby( 'customer_id' ).sum()\n",
    "                                                           .reset_index()\n",
    "                                                           .rename( columns={'quantity': 'qtde_items'} ) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "qtde_products    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de produtos\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'stock_code']].groupby( 'customer_id' ).count()\n",
    "                                                           .reset_index()\n",
    "                                                           .rename( columns={'stock_code': 'qtde_products'} ) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "qtde_products    0\n",
       "avg_ticket       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg Ticket\n",
    "df_avg_ticket = df2_purchases.loc[:, ['customer_id', 'gross_revenue']].groupby( 'customer_id' ).mean().reset_index().rename( columns={'gross_revenue':'avg_ticket'} )\n",
    "df_ref = pd.merge( df_ref, df_avg_ticket, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average recency days\n",
    "df_aux = df2[['customer_id', 'invoice_date']].drop_duplicates().sort_values( ['customer_id', 'invoice_date'], ascending= False )\n",
    "df_aux['next_customer_id'] = df_aux['customer_id'].shift() # next customer\n",
    "df_aux['previous_date'] = df_aux['invoice_date'].shift() # next invoince date\n",
    "\n",
    "df_aux['avg_recency_days'] = df_aux.apply( lambda x: ( x['previous_date'] - x['invoice_date'] ).days if x['customer_id'] == x['next_customer_id'] else 0, axis=1 )\n",
    "df_aux['avg_recency_days'] = -1* df_aux['avg_recency_days'].apply( lambda x: 1/x if x!=0 else 1)\n",
    "\n",
    "df_aux = df_aux.drop( ['invoice_date', 'next_customer_id', 'previous_date'], axis=1 ).dropna()\n",
    "\n",
    "# average recency \n",
    "df_avg_recency_days = df_aux.groupby( 'customer_id' ).mean().reset_index()\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_avg_recency_days, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frquency\n",
    "df_aux = ( df2_purchases[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id')\n",
    "                                                             .agg( max_ = ( 'invoice_date', 'max' ), \n",
    "                                                                   min_ = ( 'invoice_date', 'min' ),\n",
    "                                                                   days_= ( 'invoice_date', lambda x: ( ( x.max() - x.min() ).days ) + 1 ),\n",
    "                                                                   buy_ = ( 'invoice_no', 'count' ) ) ).reset_index()\n",
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply( lambda x: x['buy_'] / x['days_'] if  x['days_'] != 0 else 0, axis=1 )\n",
    "\n",
    "# Merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left' )\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "qtde_returns        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Returns\n",
    "df_returns = df2_returns[['customer_id', 'quantity']].groupby( 'customer_id' ).sum().reset_index().rename( columns={'quantity':'qtde_returns'} )\n",
    "df_returns['qtde_returns'] = df_returns['qtde_returns'] * -1\n",
    "df_returns['qtde_returns'] = df_returns['qtde_returns'].apply( lambda x: 1/x if x!= 0 else 0)\n",
    "\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_returns, how='left', on='customer_id' )\n",
    "df_ref.loc[df_ref['qtde_returns'].isna(), 'qtde_returns'] = 0\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "qtde_returns        0\n",
       "avg_basket_size     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg_basket_size\n",
    "df_aux = ( df2_purchases.loc[:, ['customer_id', 'invoice_no', 'quantity']].groupby( 'customer_id' )\n",
    "                                                                            .agg( n_purchase=( 'invoice_no', 'nunique'),\n",
    "                                                                                  n_products=( 'quantity', 'sum' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'avg_basket_size']], how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id               0\n",
       "gross_revenue             0\n",
       "recency_days              0\n",
       "qtde_invoices             0\n",
       "qtde_items                0\n",
       "qtde_products             0\n",
       "avg_ticket                0\n",
       "avg_recency_days          0\n",
       "frequency                 0\n",
       "qtde_returns              0\n",
       "avg_basket_size           0\n",
       "avg_unique_basket_size    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg_unique_basket_size\n",
    "df_aux = ( df2_purchases.loc[:, ['customer_id', 'invoice_no', 'stock_code']].groupby( 'customer_id' )\n",
    "                                                                            .agg( n_purchase=( 'invoice_no', 'nunique'),\n",
    "                                                                                   n_products=( 'stock_code', 'nunique' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_unique_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'avg_unique_basket_size']], how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74118/428756391.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customers_return.loc[:, 'revenue_returned'] = customers_return.loc[:, 'quantity'] * customers_return.loc[:, 'unit_price']\n"
     ]
    }
   ],
   "source": [
    "# money returned\n",
    "customers_return = df2[df2['quantity']< 0]\n",
    "customers_return.loc[:, 'revenue_returned'] = customers_return.loc[:, 'quantity'] * customers_return.loc[:, 'unit_price']\n",
    "revenue_returned = customers_return.groupby('customer_id')['revenue_returned'].sum().reset_index()\n",
    "revenue_returned['revenue_returned'] = revenue_returned['revenue_returned']\n",
    "\n",
    "df_ref = pd.merge(df_ref, revenue_returned, on='customer_id', how='left')\n",
    "df_ref = df_ref.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = df_ref.dropna()\n",
    "df4 = df_ref.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Estudo de Espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_no_scale = df4.drop( columns=['customer_id'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.4 Tree-Based Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4_no_scale.drop( columns=['gross_revenue'], axis=1 )\n",
    "y = df4_no_scale['gross_revenue']\n",
    "\n",
    "# model definition\n",
    "rf = RandomForestRegressor( n_estimators=100,\n",
    "                           criterion='friedman_mse',\n",
    "                           random_state=42)\n",
    "# model training\n",
    "rf.fit(X, y)\n",
    "\n",
    "# dataframe leaf\n",
    "df_leaf = pd.DataFrame( rf.apply( X ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natan/miniconda3/envs/clusterenv/lib/python3.11/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP( n_neighbors=20, random_state=42, n_components=3 )\n",
    "embedding = reducer.fit_transform( df_leaf )\n",
    "\n",
    "# embedding\n",
    "df_tree = pd.DataFrame()\n",
    "df_tree['embedding_x'] = embedding[:, 0]\n",
    "df_tree['embedding_y'] = embedding[:, 1]\n",
    "df_tree['embedding_z'] = embedding[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Hyperparameter Fine-Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df_tree.copy()\n",
    "X = df7.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Machine Learnign Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "\n",
    "# model trainig \n",
    "kmeans.fit ( X )\n",
    "\n",
    "# clustering\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSS value: 34674.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS Value: 0.6244341135025024\n"
     ]
    }
   ],
   "source": [
    "# WSS \n",
    "print( f'WSS value: {kmeans.inertia_}')\n",
    "\n",
    "# Silhouette\n",
    "print(f'SS Value: {metrics.silhouette_score( X, labels, metric=\"euclidean\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0 Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = X.copy()\n",
    "df9['cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['cluster'] = labels\n",
    "df9 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9['recency_days'] = df9['recency_days'].apply( lambda x: 1/ x if x != 0 else 0)\n",
    "df9['qtde_returns'] = df9['qtde_returns'].apply( lambda x: 1/ x if x != 0 else 0)\n",
    "df9['avg_recency_days'] = df9['avg_recency_days'].apply( lambda x: 1/ x if x != 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customers\n",
    "df_cluster = df9[['customer_id', 'cluster']].groupby('cluster').count().reset_index()\n",
    "df_cluster['per_customer'] = 100 * df_cluster['customer_id'] / df_cluster['customer_id'].sum()\n",
    "\n",
    "# Avg revenue\n",
    "df_avg_revenue = df9[['gross_revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_revenue, on='cluster', how='inner')\n",
    "\n",
    "# Avg recency\n",
    "df_avg_recency = df9[['recency_days', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_recency, on='cluster', how='inner')\n",
    "\n",
    "# purchases\n",
    "df_avg_frequency = df9[['qtde_invoices', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_frequency, on='cluster', how='inner')\n",
    "\n",
    "# # Avg Ticket\n",
    "# df_avg_ticket = df9[['revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "# df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# returns\n",
    "df_avg_ticket = df9[['qtde_returns', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# product_quantity\n",
    "df_avg_ticket = df9[['qtde_products', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# avg_frquency\n",
    "df_avg_ticket = df9[['frequency', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# quantity\n",
    "df_avg_ticket = df9[['avg_basket_size', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# AVG revenue returned\n",
    "df_avg_money_returned = df9.groupby('cluster')['revenue_returned'].mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_money_returned, on='cluster', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>per_customer</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>qtde_invoices</th>\n",
       "      <th>qtde_returns</th>\n",
       "      <th>qtde_products</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>revenue_returned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>8.656716</td>\n",
       "      <td>11075.384199</td>\n",
       "      <td>30.144016</td>\n",
       "      <td>14.811359</td>\n",
       "      <td>297.584178</td>\n",
       "      <td>354.436105</td>\n",
       "      <td>0.126647</td>\n",
       "      <td>822.425366</td>\n",
       "      <td>-465.533895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>533</td>\n",
       "      <td>9.359087</td>\n",
       "      <td>2884.956210</td>\n",
       "      <td>73.388368</td>\n",
       "      <td>5.022514</td>\n",
       "      <td>18.035647</td>\n",
       "      <td>212.742964</td>\n",
       "      <td>0.353365</td>\n",
       "      <td>556.521769</td>\n",
       "      <td>-35.583508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>727</td>\n",
       "      <td>12.765584</td>\n",
       "      <td>1576.121733</td>\n",
       "      <td>56.716644</td>\n",
       "      <td>4.412655</td>\n",
       "      <td>14.579092</td>\n",
       "      <td>100.455296</td>\n",
       "      <td>0.163218</td>\n",
       "      <td>295.073072</td>\n",
       "      <td>-33.048776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>208</td>\n",
       "      <td>3.652327</td>\n",
       "      <td>1492.949279</td>\n",
       "      <td>162.004808</td>\n",
       "      <td>1.043269</td>\n",
       "      <td>0.649038</td>\n",
       "      <td>165.158654</td>\n",
       "      <td>0.983023</td>\n",
       "      <td>422.480769</td>\n",
       "      <td>-0.421635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>396</td>\n",
       "      <td>6.953468</td>\n",
       "      <td>1118.087904</td>\n",
       "      <td>104.368687</td>\n",
       "      <td>2.595960</td>\n",
       "      <td>9.676768</td>\n",
       "      <td>98.833333</td>\n",
       "      <td>0.457416</td>\n",
       "      <td>287.428344</td>\n",
       "      <td>-20.240707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>417</td>\n",
       "      <td>7.322212</td>\n",
       "      <td>872.648129</td>\n",
       "      <td>87.182254</td>\n",
       "      <td>2.733813</td>\n",
       "      <td>5.038369</td>\n",
       "      <td>53.784173</td>\n",
       "      <td>0.288559</td>\n",
       "      <td>213.504077</td>\n",
       "      <td>-14.732326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>376</td>\n",
       "      <td>6.602283</td>\n",
       "      <td>548.072021</td>\n",
       "      <td>97.321809</td>\n",
       "      <td>2.210106</td>\n",
       "      <td>3.678191</td>\n",
       "      <td>42.821809</td>\n",
       "      <td>0.426589</td>\n",
       "      <td>186.620966</td>\n",
       "      <td>-10.138697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>794</td>\n",
       "      <td>13.942054</td>\n",
       "      <td>442.860227</td>\n",
       "      <td>136.267003</td>\n",
       "      <td>1.714106</td>\n",
       "      <td>2.068010</td>\n",
       "      <td>41.696474</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>128.424160</td>\n",
       "      <td>-7.282380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822</td>\n",
       "      <td>14.433714</td>\n",
       "      <td>259.274185</td>\n",
       "      <td>162.371046</td>\n",
       "      <td>1.238443</td>\n",
       "      <td>1.709246</td>\n",
       "      <td>16.588808</td>\n",
       "      <td>0.828490</td>\n",
       "      <td>108.228994</td>\n",
       "      <td>-5.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>420</td>\n",
       "      <td>7.374890</td>\n",
       "      <td>149.508143</td>\n",
       "      <td>186.366667</td>\n",
       "      <td>1.123810</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>13.578571</td>\n",
       "      <td>0.956112</td>\n",
       "      <td>37.346769</td>\n",
       "      <td>-3.009095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>509</td>\n",
       "      <td>8.937665</td>\n",
       "      <td>19.957466</td>\n",
       "      <td>195.803536</td>\n",
       "      <td>1.011788</td>\n",
       "      <td>0.587426</td>\n",
       "      <td>3.506876</td>\n",
       "      <td>0.998115</td>\n",
       "      <td>5.746234</td>\n",
       "      <td>-1.696680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  customer_id  per_customer  gross_revenue  recency_days  \\\n",
       "0         0          493      8.656716   11075.384199     30.144016   \n",
       "5         5          533      9.359087    2884.956210     73.388368   \n",
       "7         7          727     12.765584    1576.121733     56.716644   \n",
       "2         2          208      3.652327    1492.949279    162.004808   \n",
       "4         4          396      6.953468    1118.087904    104.368687   \n",
       "9         9          417      7.322212     872.648129     87.182254   \n",
       "6         6          376      6.602283     548.072021     97.321809   \n",
       "10       10          794     13.942054     442.860227    136.267003   \n",
       "1         1          822     14.433714     259.274185    162.371046   \n",
       "8         8          420      7.374890     149.508143    186.366667   \n",
       "3         3          509      8.937665      19.957466    195.803536   \n",
       "\n",
       "    qtde_invoices  qtde_returns  qtde_products  frequency  avg_basket_size  \\\n",
       "0       14.811359    297.584178     354.436105   0.126647       822.425366   \n",
       "5        5.022514     18.035647     212.742964   0.353365       556.521769   \n",
       "7        4.412655     14.579092     100.455296   0.163218       295.073072   \n",
       "2        1.043269      0.649038     165.158654   0.983023       422.480769   \n",
       "4        2.595960      9.676768      98.833333   0.457416       287.428344   \n",
       "9        2.733813      5.038369      53.784173   0.288559       213.504077   \n",
       "6        2.210106      3.678191      42.821809   0.426589       186.620966   \n",
       "10       1.714106      2.068010      41.696474   0.650830       128.424160   \n",
       "1        1.238443      1.709246      16.588808   0.828490       108.228994   \n",
       "8        1.123810      0.845238      13.578571   0.956112        37.346769   \n",
       "3        1.011788      0.587426       3.506876   0.998115         5.746234   \n",
       "\n",
       "    revenue_returned  \n",
       "0        -465.533895  \n",
       "5         -35.583508  \n",
       "7         -33.048776  \n",
       "2          -0.421635  \n",
       "4         -20.240707  \n",
       "9         -14.732326  \n",
       "6         -10.138697  \n",
       "10         -7.282380  \n",
       "1          -5.005401  \n",
       "8          -3.009095  \n",
       "3          -1.696680  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.sort_values('gross_revenue', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.0 Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Database connection details\n",
    "host = 'cluter-db.cx0iy0e6kyf8.sa-east-1.rds.amazonaws.com'\n",
    "port = '5432'\n",
    "database = 'postgres'\n",
    "user = 'natan'\n",
    "pwd = 'natan2019'\n",
    "\n",
    "# Connection string\n",
    "endpoint = f'postgresql://{user}:{pwd}@{host}:{port}/{database}'\n",
    "conn = create_engine( endpoint )\n",
    "\n",
    "# # SQL query to create the table\n",
    "# query_create_table_insiders = \"\"\"\n",
    "#     CREATE TABLE insiders (\n",
    "#         customer_id             INTEGER,\n",
    "#         gross_revenue           REAL,\n",
    "#         recency_days            REAL,\n",
    "#         qtde_invoices           INTEGER,\n",
    "#         qtde_items              INTEGER,\n",
    "#         qtde_products           INTEGER,\n",
    "#         avg_ticket              REAL,\n",
    "#         avg_recency_days        REAL,\n",
    "#         frequency               REAL,\n",
    "#         qtde_returns            REAL,\n",
    "#         avg_basket_size         REAL,\n",
    "#         avg_unique_basket_size  REAL,\n",
    "#         revenue_returned        REAL,\n",
    "#         cluster                 INTEGER\n",
    "#     )\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute the query as raw SQL\n",
    "# with engine.connect() as conn:\n",
    "#     conn.execute(text(query_create_table_insiders))\n",
    "\n",
    "# Assuming df9 is your DataFrame\n",
    "df9.to_sql('insiders', con=conn, if_exists='append', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "engine.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
